# -*- coding: utf-8 -*-
"""Images_preprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nRaWGfLJBWppcQpowFjDhShrYvFPrXX_
"""

# import required libraries
import cv2
import numpy as np
from matplotlib import pyplot as plt
from PIL import Image
import os

#Color ranges in HSV color model in dictionary form
color_dict_HSV = {'black': [[180, 255, 30], [0, 0, 0]],
              'white': [[180, 18, 255], [0, 0, 231]],
              'red1': [[180, 255, 255], [159, 50, 70]],
              'red2': [[9, 255, 255], [0, 50, 70]],
              'green': [[89, 255, 255], [36, 50, 70]],
              'blue': [[128, 255, 255], [120, 50, 70]],
              'yellow': [[35, 255, 255], [25, 50, 70]],
              'purple': [[158, 255, 255], [129, 50, 70]],
              'orange': [[24, 255, 255], [10, 50, 70]],
              'gray': [[180, 18, 230], [0, 0, 40]]}

#save the dataset path
icdar2015_dataset_path="/content/drive/MyDrive/PSENet_collab/data/icdar-2015-original/Images/Test/"
#save the result path obtained from testing the craft model on the dataset
test_cam_path="/content/drive/MyDrive/Craft_text_detection/CRAFT-pytorch/result/"
#use os library to iterate through the dataset
test_files=os.listdir(icdar2015_dataset_path)
for file in test_files:
    # read input CAM image
    img = cv2.imread(test_cam_path+'res_'+file.split(".")[0]+'_mask.jpg')
    #get the shape of the input CAM image
    h, w, channels = img.shape
    #Width-wise cutting the CAM image into half
    half = w//2
    img = img[:, :half]
    #read the input image corresponding to the input CAM image
    image=cv2.imread(icdar2015_dataset_path+file)
    #resizing the CAM image to the shape same as the input image
    img=cv2.resize(img,(image.shape[1],image.shape[0]))
    # Convert BGR to HSV
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)

    # define range of blue color in HSV
    lower_blue = np.array(color_dict_HSV['blue'][1])
    upper_blue = np.array(color_dict_HSV['blue'][0])



    # Create a mask. Threshold the HSV image to get only blue colors
    mask_blue = cv2.inRange(hsv, lower_blue, upper_blue)

    #create plain-white images of same shape as that of the input image
    mask_blue3 = 255.0*np.ones(image.shape, dtype="uint8")
    mask_blue_inv3= 255.0*np.ones(image.shape, dtype="uint8")

    #make each channel of the mask_blue3 same as mask_blue
    mask_blue3[:,:,0] = mask_blue
    mask_blue3[:,:,1] = mask_blue
    mask_blue3[:,:,2] = mask_blue

    #using bitwise_not operation to create inverted mask
    mask_blue_inv=cv2.bitwise_not(mask_blue)

    #make each channel of the mask_blue_inv3 same as mask_blue_inv
    mask_blue_inv3[:,:,0] = mask_blue_inv
    mask_blue_inv3[:,:,1] = mask_blue_inv
    mask_blue_inv3[:,:,2] = mask_blue_inv
    #take the desired values of txt weight and bg_weight
    txt_weight=1
    bg_weight=0.9
    #initialise background region weight and text region weight
    bg_weight=bg_weight*(mask_blue3/255)
    txt_weight=txt_weight*(mask_blue_inv3/255)

    #extract the text region my using the text region weight
    tmp_txt=txt_weight*image
    ext_txt=Image.fromarray(np.array(tmp_txt).astype(np.uint8))
    #extract the background region by using the background region weight
    tmp_bg=bg_weight*image
    ext_bg=Image.fromarray(np.array(tmp_bg).astype(np.uint8))

    #use bitwise OR operation on the text and background regions extracted to combine them into a single image
    tmp_final=cv2.bitwise_or(tmp_txt,tmp_bg)
    #convert it into numpy array
    tmp_final=np.array(tmp_final,dtype="uint8")
    #convert it into an image
    final_image=Image.fromarray(tmp_final)
    #name the image
    image_filename =file.split(".")[0]+".jpg"
    #save the image file
    final_image.save(image_filename)